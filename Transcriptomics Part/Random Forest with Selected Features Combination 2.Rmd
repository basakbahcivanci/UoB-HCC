---
title: "Random Forest with Selected Features Combination 2"
author: "Basak"
date: "7/1/2021"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls())
library(dplyr)
library(tibble)
library(caret)
library(ggplot2)
library(mlbench)
require(caret)
require(randomForest)
require(Boruta)
```
### Reading data sets 
```{r}
rank3 = read.csv('new_boruta_ranking_data3.csv', row.names = 1, header = TRUE)
rank4 = read.csv('new_boruta_ranking_data4.csv', row.names = 1, header = TRUE)
rank6 = read.csv('new_boruta_ranking_data6.csv', row.names = 1, header = TRUE)
# filtering confirmed Boruta selected features


#`ADH1B` `TUBA1B` `MCM6` are removed since they werent included in validation set 3 (DEG)

rank4 = rank4 %>% 
  rownames_to_column('genes') %>%
  filter(decision %in% c("Confirmed"))

rank4 = rank4 %>%
  filter(!(genes %in% c('ADH1B','TUBA1B', 'MCM6')))

rank6 = rank6 %>% 
  rownames_to_column('genes') %>%
  filter(decision %in% c("Confirmed"))

rank6 = rank6 %>%
  filter(!(genes %in% c('ADH1B','TUBA1B', 'MCM6')))

rank6[1:5,]
```

## Getting common features from ranked dataframes. 

#### Here, "common.ranking.4" has common genes with their ranking in HCCDB4 dataset and "common.ranking.6" has common genes with their ranking in HCCDB6 dataset. Common genes are ranked with different orders for HCCDB4 data and HCCDB6 data. Below codes checks these two dataframes iteratively and selects top 2, 4, 8, and all 16 genes considering both datasets.


```{r}

common = rank4[which(rank4$genes %in% rank6$genes),]



top=c()
top_list = list()

for (i in 1:dim(rank6)[1]){
  r4 = rank4[1:i,]
  r6 = rank6[1:i,]
  top = r6[which(r6$genes %in% r4$genes),"genes"]
  j = 1
  while ( 2^j <= dim(rank4)[1]){
    if (length(top) == 2^j) {
      name <- paste("top", 2^j, sep = "")
      assign(name, top)
      # cat("Top",2^j, "genes: ", top, '\n') # printing & checking each iteration
      top_list[[name]] <- top
    }
    j = j+1
  }
  # to add all common genes to the top list
  if (length(top) == dim(common)[1]){ 
      name <- paste("top", dim(common)[1], sep = "")
      assign(name, top)
      top_list[[name]] <- top
  }
}
top_list
write.csv( top_list$top8, "top_list3-8.csv", quote = F,row.names = F)

```
## Random Forest 
### Train: HCCDB4 Data (Train set)
### Test: HCCDB4 Data (Test set), HCCDB6 Data (Test set) 
### Validatation: HCCDB3 Data
##### Note: While using HCCDB3 as test set, only the part which is not used for Baruto Feature Selection is used. This condition is satisfied with set.seed () function for all data sets used.


#### Reading HCCDB4 data sets 
```{r}
x.4 = read.csv('DEGS_HCCDB4.csv', row.names = 1, header = TRUE)
x.4 = as.data.frame(t(x.4))

sample4_info = read.csv('prepared_sample_info4.csv', header = TRUE) 

head(sample4_info)
x.4[1:5,1:5]
```
### Scaling data (Data is already log2 transformed)
```{r}
x.4 = scale(x.4,center = TRUE, scale = TRUE)
x.4[1:5,1:5]
```
### Preparing data sets to split into test and train. Type varible (dependent variable) is added to the data as a factor.
```{r}
data4 = as.data.frame(x.4) %>% 
  rownames_to_column(var = "Samples") %>%
  left_join(sample4_info %>% select(Samples,TYPE), by = "Samples") %>%
  mutate(TYPE = as.factor(TYPE)) %>%
  column_to_rownames(var = "Samples")
```

### Generating a stratified random split of the data. 
```{r}
set.seed(11) # Always same train and test split will be used in the analysis
train4.Index <- createDataPartition(data4$TYPE, p = .7,
                                  list = FALSE,
                                  times = 1)
data4.train <- data4[train4.Index,]
test4 <- data4[-train4.Index,]
table(test4$TYPE)
table(data4.train$TYPE)

```

### Reading HCCDB6 data sets 
```{r}
x.6 = read.csv('DEGS_HCCDB6.csv', row.names = 1, header = TRUE)
x.6 = as.data.frame(t(x.6))

sample6_info = read.csv('prepared_sample_info6.csv', header = TRUE) 

head(sample6_info)
x.6[1:5,1:5]
```
### Scaling data (Data is already log2 transformed)
```{r}
x.6 = scale(x.6,center = TRUE, scale = TRUE)
x.6[1:5,1:5]
```
### Preparing data sets to split into test and train. Type varible is added to the data as a factor.
```{r}
data6 = as.data.frame(x.6) %>% 
  rownames_to_column(var = "Samples") %>%
  left_join(sample6_info %>% select(Samples,TYPE), by = "Samples") %>%
  mutate(TYPE = as.factor(TYPE)) %>%
  column_to_rownames(var = "Samples")
```

### Generating a stratified random split of the data
```{r}
set.seed(11) # Always same train and test split will be used in the analysis
train6.Index <- createDataPartition(data6$TYPE, p = .7,
                                  list = FALSE,
                                  times = 1)
data6.train <- data6[train6.Index,]
test6 <- data6[-train6.Index,]
table(test6$TYPE)
table(data6.train$TYPE)
```
```{r}

```

### Reading HCCDB3 data sets (Validation)
```{r}
x.3 = read.csv('DEGS_HCCDB3.csv', row.names = 1, header = TRUE)
x.3 = as.data.frame(t(x.3))

sample3_info = read.csv('prepared_sample_info3.csv', header = TRUE) 

head(sample3_info)
x.3[1:5,1:5]
```

### Scaling data (Data is already log2 transformed)
```{r}
x.3 = scale(x.3, center = TRUE, scale = TRUE)
x.3[1:5,1:5]
```

### Preparing data sets to split into test and train. Type varible is added to the data as a factor.
```{r}
validation.3 = as.data.frame(x.3) %>% 
  rownames_to_column(var = "Samples") %>%
  left_join(sample3_info %>% select(Samples,TYPE), by = "Samples") %>%
  mutate(TYPE = as.factor(TYPE)) %>%
  column_to_rownames(var = "Samples")
```

```{r}
# A list that contains a number of custom named elements that the caret package looks for, such as how to fit and how to predict. 
# Define a custom RF (Classification) method to allow optimisation of ntree parameter as well as mtry.
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), 
                                  class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
  predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
  predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes

# train model
control <- trainControl(method="repeatedcv", number=10, repeats=10, classProbs = TRUE)
```

### Random Forest with top 2 genes 
```{r}

data4.train.top2 = data4.train %>%
  select(TYPE,top_list[["top2"]])

# Define values for mtry and ntree to explore. 
# For mtry assess 1 and 2 (since there are 2 genes)
tunegrid <- expand.grid(.mtry=c(1,2), 
                        .ntree=c(1000, 1500, 2000, 2500, 3000, 3500))
custom.top2 <- train(TYPE~., data=data4.train.top2, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
plot(custom.top2)

```


### Fitting the best model on train set 6, then predicting on test 6, test 3 and validation set 4
```{r}
tunegrid <- expand.grid(.mtry = 1, .ntree =2500)
custom.top2 <- train(TYPE~., data=data4.train.top2, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
# Prepare Test sets and Validation set for top 2 genes
test4.top2 = test4 %>%
  select(TYPE,top_list[["top2"]])
test6.top2 = test6 %>%
  select(TYPE,top_list[["top2"]])
validation.3.top2 = validation.3 %>%
  select(TYPE,top_list[["top2"]])

prediction4 = predict(custom.top2,test4.top2,'prob')
prediction6 = predict(custom.top2,test6.top2,'prob')
prediction3 = predict(custom.top2,validation.3.top2,'prob')
```

```{r}
pdf(file = "Combination 3 - ROC Curves for 2 Genes.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 8.5) # The height of the plot in inches

par(pty="s") 
lrROC <- roc(test4.top2$TYPE ~ prediction4$HCC,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.75,
             col="red",
             lwd =1.5,legacy.axes=TRUE,main="ROC Curves for 2 Genes")
lrROC <- roc(test6.top2$TYPE ~ prediction6$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.4,print.auc.y = 0.93,
             col="orange",
             lwd =1.5,legacy.axes=TRUE)
lrROC <- roc(validation.3.top2$TYPE ~ prediction3$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.45,
             col="blue",
             lwd =1.5,legacy.axes=TRUE)
legend("bottomright",cex = 0.65,xjust = 1,legend=c('HCCDB4 Test set','HCCDB6 Test set','HCCDB3 Validation Set',
                                                   "mtry = 1","ntree = 2500"),
       col=c('red','orange','blue','black','black'),lwd=1)
dev.off()

```


### Random Forest with top 4 genes 
```{r}
data4.train.top4 = data4.train %>%
  select(TYPE,top_list[["top4"]])
mtry <- sqrt(ncol(data4.train.top4)-1)
# Define values for mtry and ntree to explore. 
# For mtry assess 50%, 100%, and 150% of the default value.
tunegrid <- expand.grid(.mtry=c(round(0.5*mtry),round(mtry),round(1.5*mtry)), 
                        .ntree=c(1000, 1500, 2000, 2500, 3000))
custom.top4 <- train(TYPE~., data=data4.train.top4, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
plot(custom.top4)
```

### Fitting the best model on train set 6, then predicting on test 6, test 3 and validation set 4
```{r}
tunegrid <- expand.grid(.mtry = 1, .ntree =1500)
custom.top4 <- train(TYPE~., data=data4.train.top4, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
# Prepare Test sets and Validation set for top 2 genes
test4.top4 = test4 %>%
  select(TYPE,top_list[["top4"]])
test6.top4 = test6 %>%
  select(TYPE,top_list[["top4"]])
validation.3.top4 = validation.3 %>%
  select(TYPE,top_list[["top4"]])

prediction4 = predict(custom.top4,test4.top4,'prob')
prediction6 = predict(custom.top4,test6.top4,'prob')
prediction3 = predict(custom.top4,validation.3.top4,'prob')
```


```{r}
pdf(file = "Combination 3 - ROC Curves for 4 Genes.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 8.5) # The height of the plot in inches

par(pty="s") 
lrROC <- roc(test4.top4$TYPE ~ prediction4$HCC,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.75,
             col="red",
             lwd =1.5,legacy.axes=TRUE,main="ROC Curves for 4 Genes")
lrROC <- roc(test6.top4$TYPE ~ prediction6$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.4,print.auc.y = 0.93,
             col="orange",
             lwd =1.5,legacy.axes=TRUE)
lrROC <- roc(validation.3.top4$TYPE ~ prediction3$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.45,
             col="blue",
             lwd =1.5,legacy.axes=TRUE)
legend("bottomright",cex = 0.65,xjust = 1,legend=c('HCCDB4 Test set','HCCDB6 Test set','HCCDB3 Validation Set',
                                                   "mtry = 1","ntree = 1500"),
       col=c('red','orange','blue','black','black'),lwd=1)
dev.off()

```

### Random Forest with top 8 genes 
```{r}
data4.train.top8 = data4.train %>%
  select(TYPE,top_list[["top8"]])
mtry <- sqrt(ncol(data4.train.top8)-1)
# Define values for mtry and ntree to explore. 
# For mtry assess 50%, 100%, and 150% of the default value.
tunegrid <- expand.grid(.mtry=c(round(0.5*mtry),round(mtry),round(1.5*mtry)), 
                        .ntree=c(1000, 1500, 2000, 2500, 3000))
custom.top8 <- train(TYPE~., data=data4.train.top8, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
plot(custom.top8)
```

### Fitting the best model on train set 6, then predicting on test 6, test 3 and validation set 4
```{r}
tunegrid <- expand.grid(.mtry = round(0.5*mtry), .ntree =1000)
custom.top8 <- train(TYPE~., data=data4.train.top8, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
# Prepare Test sets and Validation set for top 8 genes
test4.top8 = test4 %>%
  select(TYPE,top_list[["top8"]])
test6.top8 = test6 %>%
  select(TYPE,top_list[["top8"]])
validation.3.top8 = validation.3 %>%
  select(TYPE,top_list[["top8"]])
prediction4 = predict(custom.top8,test4.top8,'prob')
prediction6 = predict(custom.top8,test6.top8,'prob')
prediction3 = predict(custom.top8,validation.3.top8,'prob')

```

```{r}
pdf(file = "Combination 3 - ROC Curves for 8 Genes.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 8.5) # The height of the plot in inches

par(pty="s") 
lrROC <- roc(test4.top8$TYPE ~ prediction4$HCC,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.75,
             col="red",
             lwd =1.5,legacy.axes=TRUE,main="ROC Curves for 8 Genes")
lrROC <- roc(test6.top8$TYPE ~ prediction6$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.4,print.auc.y = 0.93,
             col="orange",
             lwd =1.5,legacy.axes=TRUE)
lrROC <- roc(validation.3.top8$TYPE ~ prediction3$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.45,
             col="blue",
             lwd =1.5,legacy.axes=TRUE)
legend("bottomright",cex = 0.65,xjust = 1,legend=c('HCCDB4 Test set','HCCDB6 Test set','HCCDB3 Validation Set',
                                                   "mtry = 1","ntree = 1000"),
       col=c('red','orange','blue','black','black'),lwd=1)
dev.off()
```

### Random Forest with top 13 genes 
```{r}
data4.train.top13 = data4.train %>%
  select(TYPE,top_list[["top13"]])
mtry <- sqrt(ncol(data4.train.top13)-1)
# Define values for mtry and ntree to explore. 
# For mtry assess 50%, 100%, and 150% of the default value.
tunegrid <- expand.grid(.mtry=c(round(0.5*mtry),round(mtry),round(1.5*mtry)), 
                        .ntree=c(1000, 1500, 2000, 2500, 3000))
custom.top13 <- train(TYPE~., data= data4.train.top13, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
plot(custom.top13)

```

### Fitting the best model on train set 6, then predicting on test 6, test 3 and validation set 4
```{r}
tunegrid <- expand.grid(.mtry = round(1.5*mtry), .ntree =1000)
custom.top13 <- train(TYPE~., data=data4.train.top13, 
                 method=customRF, 
                 metric='Accuracy', 
                 tuneGrid=tunegrid, 
                 trControl=control, 
                 verbose=T) 
# Prepare Test sets and Validation set for top 13 genes
test4.top13 = test4 %>%
  select(TYPE,top_list[["top13"]])
test6.top13 = test6 %>%
  select(TYPE,top_list[["top13"]])
validation.3.top13 = validation.3 %>%
  select(TYPE,top_list[["top13"]])
prediction4 = predict(custom.top13,test4.top13,'prob')
prediction6 = predict(custom.top13,test6.top13,'prob')
prediction3 = predict(custom.top13,validation.3.top13,'prob')

```

```{r}
pdf(file = "Combination 3 - ROC Curves for 13 Genes.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 8.5) # The height of the plot in inches

par(pty="s") 
lrROC <- roc(test4.top13$TYPE ~ prediction4$HCC,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.75,
             col="red",
             lwd =1.5,legacy.axes=TRUE,main="ROC Curves for 13 Genes")
lrROC <- roc(test6.top13$TYPE ~ prediction6$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.4,print.auc.y = 0.93,
             col="orange",
             lwd =1.5,legacy.axes=TRUE)
lrROC <- roc(validation.3.top13$TYPE ~ prediction3$HCC,add = TRUE,plot=TRUE,
             print.auc=T,print.auc.x = 0.9,print.auc.y = 0.45,
             col="blue",
             lwd =1.5,legacy.axes=TRUE)
legend("bottomright",cex = 0.65,xjust = 1,legend=c('HCCDB4 Test set','HCCDB6 Test set','HCCDB3 Validation Set',
                                                   "mtry = 5","ntree = 1000"),
       col=c('red','orange','blue','black','black'),lwd=1)
dev.off()
```


